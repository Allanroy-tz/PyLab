{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ChinaBank = pd.read_csv('ChinaBank.csv', index_col='Date', parse_dates=[\n",
    "                        'Date']).drop(labels=\"Unnamed: 0\", axis=1)\n",
    "#ChinaBank.index = pd.to_datetime(ChinaBank.index)\n",
    "sub = ChinaBank['2014-01':'2014-04']\n",
    "train = sub.loc['2014-01':'2014-03']\n",
    "testDf = sub.loc['2014-04-01':'2014-04-30']\n",
    "plt.figure(figsize=(10, 10))\n",
    "print(sub.loc['2014-01':'2014-03'])\n",
    "plt.plot(train[\"Close\"], color='red', label=\"Close\")\n",
    "plt.plot(train[\"Open\"], color='green', label=\"Open\")\n",
    "plt.plot(train[\"High\"], color='blue', label=\"High\")\n",
    "plt.plot(train[\"Low\"], color='skyblue', label=\"Low\")\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.yticks(np.arange(2.4, 2.7, 0.01))\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(train[\"Volume\"], color='black', label=\"Volum\")\n",
    "plt.legend()\n",
    "plt.yticks(np.arange(0, train[\"Volume\"].max()+1e7, 1e7))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "'''训练数据维度'''\n",
    "dimension = 3\n",
    "nptrain = train.to_numpy()\n",
    "# print(nptrain)\n",
    "u, s, vt = np.linalg.svd(nptrain)\n",
    "'''降维'''\n",
    "svdtrain = np.dot(vt[:dimension, :], np.mat(nptrain).T).T\n",
    "predict_sunspots02 = np.dot(svdtrain, vt[:dimension, :])\n",
    "print(r2_score(nptrain, predict_sunspots02))\n",
    "# print(predict_sunspots02)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(predict_sunspots02[..., 3], color='red', label=\"Close\")\n",
    "plt.plot(predict_sunspots02[..., 0], color='green', label=\"Open\")\n",
    "plt.plot(predict_sunspots02[..., 1], color='blue', label=\"High\")\n",
    "plt.plot(predict_sunspots02[..., 2], color='skyblue', label=\"Low\")\n",
    "# plt.plot(train[\"Volume\"],color='blacl')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(predict_sunspots02[..., 4], color='black', label=\"Volum\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# print(svdtrain)\n",
    "dataFrame = pd.DataFrame(svdtrain).set_index(train.index)\n",
    "print(dataFrame.shape)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(dataFrame)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#格兰杰检验\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "maxlag = 12\n",
    "test = 'ssr_chi2test'\n",
    "variables = dataFrame.columns\n",
    "\n",
    "\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))),\n",
    "                      columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1], 4)for i in range(maxlag)]\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [str(var) + '_x' for var in variables]\n",
    "    df.index = [str(var) + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "\n",
    "grangers_causation_matrix(train, variables=train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF检验\n",
    "def adfuller_test(series, signif=0.05, name='', verbose=False):\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic': round(r[0], 4), 'pvalue': round(\n",
    "        r[1], 4), 'n_lags': round(r[2], 4), 'n_obs': r[3]}\n",
    "    p_value = output['pvalue']\n",
    "    def adjust(val, length=6): return str(val).ljust(length)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n",
    "    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "    print(f' Significance Level    = {signif}')\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key, val in r[4].items():\n",
    "        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")\n",
    "\n",
    "\n",
    "for name, column in dataFrame.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 协整检验\n",
    "def cointegration_test(df, alpha=0.05):\n",
    "    out = coint_johansen(df, -1, 5)\n",
    "    d = {'0.90': 0, '0.95': 1, '0.99': 2}\n",
    "    \"\"\"Trace statistic\"\"\"\n",
    "    traces = out.lr1\n",
    "    \"\"\"Critical values (90%, 95%, 99%) of trace statistic\"\"\"\n",
    "    cvts = out.cvt[:, d[str(1-alpha)]]\n",
    "    def adjust(val, length=6): return str(val).ljust(length)\n",
    "\n",
    "    # Summary\n",
    "    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n",
    "    for col, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        print(adjust(col), ':: ', adjust(round(trace, 2), 9),\n",
    "              \">\", adjust(cvt, 8), ' =>  ', trace > cvt)\n",
    "\n",
    "\n",
    "cointegration_test(ChinaBank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 差分\n",
    "df_differenced = dataFrame.diff().dropna()\n",
    "for name, column in df_differenced.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择模型阶数\n",
    "model = VAR(df_differenced)\n",
    "ss=pd.DataFrame(columns={'AIC','BIC','FPE','HQIC'})\n",
    "for i in range(40):\n",
    "    result = model.fit(i+1)\n",
    "    ss.loc[str(i+1)+'阶']=[[result.aic],[result.bic],[result.fpe],[result.hqic]]\n",
    "    # print('Lag Order =', i)\n",
    "    # print('AIC : ', result.aic, '\\n')\n",
    "    # print('BIC : ', result.bic, '\\n')\n",
    "    # print('FPE : ', result.fpe, '\\n')\n",
    "    # print('HQIC : ', result.hqic, '\\n')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拟合模型\n",
    "model_fitted = model.fit(8)\n",
    "model_fitted.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#durbin watson test\n",
    "out = durbin_watson(model_fitted.resid)\n",
    "a=0\n",
    "b=0\n",
    "for col, val in zip(sub.columns, out):\n",
    "    a+=round(val, 4)\n",
    "    b=b+1\n",
    "    print(b,round(val, 4))  # 检验值越接近2，说明模型越好\n",
    "a=a/b\n",
    "print(\"平均数：\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lag_order = model_fitted.k_ar\n",
    "forecast_input = df_differenced.values[-lag_order:]\n",
    "fc = model_fitted.forecast(y=forecast_input, steps=22)\n",
    "df_forecast = pd.DataFrame(fc, index=sub.index[-22:])\n",
    "df_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#差分还原\n",
    "def invert_transformation(df_train, df_forecast):\n",
    "    df_fc = df_forecast.copy()\n",
    "    columns = df_train.columns\n",
    "    for col in columns:\n",
    "        #df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
    "        df_fc[col] = df_train[col].iloc[-1] + df_fc[col].cumsum()\n",
    "    return df_fc\n",
    "\n",
    "df_results=dataFrame\n",
    "#df_results = invert_transformation(dataFrame, df_forecast)\n",
    "#df_results\n",
    "# df_results.loc[:, ['rgnp_forecast', 'pgnp_forecast', 'ulc_forecast', 'gdfco_forecast',\n",
    "#                    'gdf_forecast', 'gdfim_forecast', 'gdfcf_forecast', 'gdfce_forecast']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=np.dot(df_results,vt[:dimension,:])\n",
    "df_results=pd.DataFrame(df_results,index=testDf.index,columns=testDf.columns+\"_Forecast\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=1, dpi=150, figsize=(5, 10))\n",
    "for i, (col, ax) in enumerate(zip(sub.columns, axes.flatten())):\n",
    "    df_results[str(col)+\"_Forecast\"].plot(legend=True,\n",
    "                                          ax=ax).autoscale(axis='x', tight=True)\n",
    "    testDf[str(col)].plot(legend=True, ax=ax)\n",
    "    ax.set_title(col + \": Forecast vs Actuals:\"+str(r2_score(df_results[str(col)+\"_Forecast\"].T,testDf[str(col)].T)))\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines[\"top\"].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
